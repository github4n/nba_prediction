{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " #首先要引入各个包\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>PTS_OFF_TOV</th>\n",
       "      <th>TEAM_NAME</th>\n",
       "      <th>FTM</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "      <th>STL</th>\n",
       "      <th>REB</th>\n",
       "      <th>PTS_PAINT</th>\n",
       "      <th>PTS_FB</th>\n",
       "      <th>...</th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>WL</th>\n",
       "      <th>FG3A</th>\n",
       "      <th>SEASON_YEAR</th>\n",
       "      <th>AST</th>\n",
       "      <th>FGM</th>\n",
       "      <th>BLKA</th>\n",
       "      <th>PTS_2ND_CHANCE</th>\n",
       "      <th>FG3M</th>\n",
       "      <th>PTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21601226</td>\n",
       "      <td>3</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-04-12T00:00:00</td>\n",
       "      <td>ATL</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>L</td>\n",
       "      <td>29</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21601212</td>\n",
       "      <td>14</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>14</td>\n",
       "      <td>2017-04-11T00:00:00</td>\n",
       "      <td>ATL</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>W</td>\n",
       "      <td>27</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21601197</td>\n",
       "      <td>20</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>29</td>\n",
       "      <td>2017-04-09T00:00:00</td>\n",
       "      <td>ATL</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>W</td>\n",
       "      <td>31</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>31</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21601179</td>\n",
       "      <td>15</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-04-07T00:00:00</td>\n",
       "      <td>ATL</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>W</td>\n",
       "      <td>37</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>39</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21601177</td>\n",
       "      <td>14</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-04-06T00:00:00</td>\n",
       "      <td>ATL</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>44</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>W</td>\n",
       "      <td>23</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>26</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21601148</td>\n",
       "      <td>28</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-04-02T00:00:00</td>\n",
       "      <td>ATL</td>\n",
       "      <td>9</td>\n",
       "      <td>44</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>L</td>\n",
       "      <td>24</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21601138</td>\n",
       "      <td>15</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>13</td>\n",
       "      <td>2017-04-01T00:00:00</td>\n",
       "      <td>ATL</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>L</td>\n",
       "      <td>28</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21601111</td>\n",
       "      <td>10</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-03-29T00:00:00</td>\n",
       "      <td>ATL</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>W</td>\n",
       "      <td>18</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21601106</td>\n",
       "      <td>12</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>21</td>\n",
       "      <td>2017-03-28T00:00:00</td>\n",
       "      <td>ATL</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>W</td>\n",
       "      <td>27</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21601088</td>\n",
       "      <td>21</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>19</td>\n",
       "      <td>2017-03-26T00:00:00</td>\n",
       "      <td>ATL</td>\n",
       "      <td>10</td>\n",
       "      <td>58</td>\n",
       "      <td>46</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>L</td>\n",
       "      <td>27</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    GAME_ID  PTS_OFF_TOV      TEAM_NAME  FTM            GAME_DATE  \\\n",
       "0  21601226            3  Atlanta Hawks   15  2017-04-12T00:00:00   \n",
       "1  21601212           14  Atlanta Hawks   14  2017-04-11T00:00:00   \n",
       "2  21601197           20  Atlanta Hawks   29  2017-04-09T00:00:00   \n",
       "3  21601179           15  Atlanta Hawks    8  2017-04-07T00:00:00   \n",
       "4  21601177           14  Atlanta Hawks   24  2017-04-06T00:00:00   \n",
       "5  21601148           28  Atlanta Hawks   15  2017-04-02T00:00:00   \n",
       "6  21601138           15  Atlanta Hawks   13  2017-04-01T00:00:00   \n",
       "7  21601111           10  Atlanta Hawks   22  2017-03-29T00:00:00   \n",
       "8  21601106           12  Atlanta Hawks   21  2017-03-28T00:00:00   \n",
       "9  21601088           21  Atlanta Hawks   19  2017-03-26T00:00:00   \n",
       "\n",
       "  TEAM_ABBREVIATION  STL  REB  PTS_PAINT  PTS_FB ...      TEAM_ID  WL  FG3A  \\\n",
       "0               ATL    5   37         30       0 ...   1610612737   L    29   \n",
       "1               ATL    6   50         50      14 ...   1610612737   W    27   \n",
       "2               ATL    8   45         58       9 ...   1610612737   W    31   \n",
       "3               ATL    7   42         42      16 ...   1610612737   W    37   \n",
       "4               ATL    7   52         44      17 ...   1610612737   W    23   \n",
       "5               ATL    9   44         34      15 ...   1610612737   L    24   \n",
       "6               ATL    4   45         46      17 ...   1610612737   L    28   \n",
       "7               ATL    7   47         38       0 ...   1610612737   W    18   \n",
       "8               ATL    5   51         36       7 ...   1610612737   W    27   \n",
       "9               ATL   10   58         46      20 ...   1610612737   L    27   \n",
       "\n",
       "   SEASON_YEAR AST  FGM  BLKA  PTS_2ND_CHANCE  FG3M  PTS  \n",
       "0      2016-17  19   30     7               3    11   86  \n",
       "1      2016-17  30   41     1               9     7  103  \n",
       "2      2016-17  31   44     3               6     9  126  \n",
       "3      2016-17  39   45     3               7    16  114  \n",
       "4      2016-17  26   44     4              25    11  123  \n",
       "5      2016-17  19   30     6               6     7   82  \n",
       "6      2016-17  25   40     4              17    11  104  \n",
       "7      2016-17  19   34     3              21     9   99  \n",
       "8      2016-17  24   34     6               8     6   95  \n",
       "9      2016-17  16   34     7              30     5   92  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.先把不需要的列删掉：涉及排名的列\n",
    "def delete_col(fn,is_print=False):\n",
    "    df = pd.read_excel(fn)\n",
    "    columns = [col for col in df.columns if not (\"RANK\" in col or \"PCT\" in col or \"RATIO\" in col or \"OPP\" in col or \"RATING\" in col or \"PIE\" in col or \"PACE\" in col or \"PLUS_MINUS\" in col or \"RATE\" in col or \"AST_TO\" in col)]\n",
    "    return df[columns]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for fn in os.listdir('../数据收集'):\n",
    "    if fn.endswith('.xlsx') and \"games\" not in fn:\n",
    "        new_df = delete_col('../数据收集/'+fn)\n",
    "        df = pd.concat([df,new_df])\n",
    "df.head(10)\n",
    "#df.to_excel(\"all_games.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = sorted(df['GAME_ID'].unique())\n",
    "group_df = df.set_index('TEAM_ABBREVIATION').groupby('GAME_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GAME_ID', 'PTS_OFF_TOV', 'TEAM_NAME', 'FTM', 'GAME_DATE',\n",
       "       'TEAM_ABBREVIATION', 'STL', 'REB', 'PTS_PAINT', 'PTS_FB', 'BLK', 'PFD',\n",
       "       'DREB', 'MIN', 'MATCHUP', 'OREB', 'TOV', 'FGA', 'FTA', 'PF', 'TEAM_ID',\n",
       "       'WL', 'FG3A', 'SEASON_YEAR', 'AST', 'FGM', 'BLKA', 'PTS_2ND_CHANCE',\n",
       "       'FG3M', 'PTS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function concat in module pandas.core.reshape.concat:\n",
      "\n",
      "concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True)\n",
      "    Concatenate pandas objects along a particular axis with optional set logic\n",
      "    along the other axes.\n",
      "    \n",
      "    Can also add a layer of hierarchical indexing on the concatenation axis,\n",
      "    which may be useful if the labels are the same (or overlapping) on\n",
      "    the passed axis number.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    objs : a sequence or mapping of Series, DataFrame, or Panel objects\n",
      "        If a dict is passed, the sorted keys will be used as the `keys`\n",
      "        argument, unless it is passed, in which case the values will be\n",
      "        selected (see below). Any None objects will be dropped silently unless\n",
      "        they are all None in which case a ValueError will be raised\n",
      "    axis : {0/'index', 1/'columns'}, default 0\n",
      "        The axis to concatenate along\n",
      "    join : {'inner', 'outer'}, default 'outer'\n",
      "        How to handle indexes on other axis(es)\n",
      "    join_axes : list of Index objects\n",
      "        Specific indexes to use for the other n - 1 axes instead of performing\n",
      "        inner/outer set logic\n",
      "    ignore_index : boolean, default False\n",
      "        If True, do not use the index values along the concatenation axis. The\n",
      "        resulting axis will be labeled 0, ..., n - 1. This is useful if you are\n",
      "        concatenating objects where the concatenation axis does not have\n",
      "        meaningful indexing information. Note the index values on the other\n",
      "        axes are still respected in the join.\n",
      "    keys : sequence, default None\n",
      "        If multiple levels passed, should contain tuples. Construct\n",
      "        hierarchical index using the passed keys as the outermost level\n",
      "    levels : list of sequences, default None\n",
      "        Specific levels (unique values) to use for constructing a\n",
      "        MultiIndex. Otherwise they will be inferred from the keys\n",
      "    names : list, default None\n",
      "        Names for the levels in the resulting hierarchical index\n",
      "    verify_integrity : boolean, default False\n",
      "        Check whether the new concatenated axis contains duplicates. This can\n",
      "        be very expensive relative to the actual data concatenation\n",
      "    copy : boolean, default True\n",
      "        If False, do not copy data unnecessarily\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    concatenated : type of objects\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The keys, levels, and names arguments are all optional.\n",
      "    \n",
      "    A walkthrough of how this method fits in with other tools for combining\n",
      "    panda objects can be found `here\n",
      "    <http://pandas.pydata.org/pandas-docs/stable/merging.html>`__.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    Series.append\n",
      "    DataFrame.append\n",
      "    DataFrame.join\n",
      "    DataFrame.merge\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Combine two ``Series``.\n",
      "    \n",
      "    >>> s1 = pd.Series(['a', 'b'])\n",
      "    >>> s2 = pd.Series(['c', 'd'])\n",
      "    >>> pd.concat([s1, s2])\n",
      "    0    a\n",
      "    1    b\n",
      "    0    c\n",
      "    1    d\n",
      "    dtype: object\n",
      "    \n",
      "    Clear the existing index and reset it in the result\n",
      "    by setting the ``ignore_index`` option to ``True``.\n",
      "    \n",
      "    >>> pd.concat([s1, s2], ignore_index=True)\n",
      "    0    a\n",
      "    1    b\n",
      "    2    c\n",
      "    3    d\n",
      "    dtype: object\n",
      "    \n",
      "    Add a hierarchical index at the outermost level of\n",
      "    the data with the ``keys`` option.\n",
      "    \n",
      "    >>> pd.concat([s1, s2], keys=['s1', 's2',])\n",
      "    s1  0    a\n",
      "        1    b\n",
      "    s2  0    c\n",
      "        1    d\n",
      "    dtype: object\n",
      "    \n",
      "    Label the index keys you create with the ``names`` option.\n",
      "    \n",
      "    >>> pd.concat([s1, s2], keys=['s1', 's2'],\n",
      "    ...           names=['Series name', 'Row ID'])\n",
      "    Series name  Row ID\n",
      "    s1           0         a\n",
      "                 1         b\n",
      "    s2           0         c\n",
      "                 1         d\n",
      "    dtype: object\n",
      "    \n",
      "    Combine two ``DataFrame`` objects with identical columns.\n",
      "    \n",
      "    >>> df1 = pd.DataFrame([['a', 1], ['b', 2]],\n",
      "    ...                    columns=['letter', 'number'])\n",
      "    >>> df1\n",
      "      letter  number\n",
      "    0      a       1\n",
      "    1      b       2\n",
      "    >>> df2 = pd.DataFrame([['c', 3], ['d', 4]],\n",
      "    ...                    columns=['letter', 'number'])\n",
      "    >>> df2\n",
      "      letter  number\n",
      "    0      c       3\n",
      "    1      d       4\n",
      "    >>> pd.concat([df1, df2])\n",
      "      letter  number\n",
      "    0      a       1\n",
      "    1      b       2\n",
      "    0      c       3\n",
      "    1      d       4\n",
      "    \n",
      "    Combine ``DataFrame`` objects with overlapping columns\n",
      "    and return everything. Columns outside the intersection will\n",
      "    be filled with ``NaN`` values.\n",
      "    \n",
      "    >>> df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],\n",
      "    ...                    columns=['letter', 'number', 'animal'])\n",
      "    >>> df3\n",
      "      letter  number animal\n",
      "    0      c       3    cat\n",
      "    1      d       4    dog\n",
      "    >>> pd.concat([df1, df3])\n",
      "      animal letter  number\n",
      "    0    NaN      a       1\n",
      "    1    NaN      b       2\n",
      "    0    cat      c       3\n",
      "    1    dog      d       4\n",
      "    \n",
      "    Combine ``DataFrame`` objects with overlapping columns\n",
      "    and return only those that are shared by passing ``inner`` to\n",
      "    the ``join`` keyword argument.\n",
      "    \n",
      "    >>> pd.concat([df1, df3], join=\"inner\")\n",
      "      letter  number\n",
      "    0      a       1\n",
      "    1      b       2\n",
      "    0      c       3\n",
      "    1      d       4\n",
      "    \n",
      "    Combine ``DataFrame`` objects horizontally along the x axis by\n",
      "    passing in ``axis=1``.\n",
      "    \n",
      "    >>> df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],\n",
      "    ...                    columns=['animal', 'name'])\n",
      "    >>> pd.concat([df1, df4], axis=1)\n",
      "      letter  number  animal    name\n",
      "    0      a       1    bird   polly\n",
      "    1      b       2  monkey  george\n",
      "    \n",
      "    Prevent the result from including duplicate index values with the\n",
      "    ``verify_integrity`` option.\n",
      "    \n",
      "    >>> df5 = pd.DataFrame([1], index=['a'])\n",
      "    >>> df5\n",
      "       0\n",
      "    a  1\n",
      "    >>> df6 = pd.DataFrame([2], index=['a'])\n",
      "    >>> df6\n",
      "       0\n",
      "    a  2\n",
      "    >>> pd.concat([df5, df6], verify_integrity=True)\n",
      "    ValueError: Indexes have overlapping values: ['a']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.concat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
